# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import numpy as np

# from dataloader import MOPVRPGenerator, get_rl_dataloader

# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import numpy as np

# # from dataloader import MOPVRPGenerator, get_rl_dataloader

# class Encoder(nn.Module):
#     """Encodes static & dynamic features using 1D Convolution."""
#     def __init__(self, input_size, hidden_size):
#         super(Encoder, self).__init__()
#         self.conv = nn.Conv1d(input_size, hidden_size, kernel_size=1)
    
#     def forward(self, x):
#         return self.conv(x)

# class MultiAgentDecoder(nn.Module):
#     """Decoder for multi-agent vehicle routing."""
#     def __init__(self, hidden_size, num_layers=1, dropout=0.2):
#         super(MultiAgentDecoder, self).__init__()
#         self.hidden_size = hidden_size
#         self.num_layers = num_layers
        
#         self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers,
#                            batch_first=True, dropout=dropout if num_layers > 1 else 0)
        
#         self.v_veh = nn.Parameter(torch.zeros((1, 1, hidden_size)))
#         self.W_veh = nn.Parameter(torch.zeros((1, hidden_size, hidden_size * 3)))
        
#         self.v_node = nn.Parameter(torch.zeros((1, 1, hidden_size)))
#         self.W_node = nn.Parameter(torch.zeros((1, hidden_size, hidden_size * 3)))
        
#         # Init weights
#         nn.init.xavier_uniform_(self.v_veh)
#         nn.init.xavier_uniform_(self.W_veh)
#         nn.init.xavier_uniform_(self.v_node)
#         nn.init.xavier_uniform_(self.W_node)
        
#         self.drop_rnn = nn.Dropout(p=dropout)
#         if num_layers == 1:
#             self.drop_hh = nn.Dropout(p=dropout)
    
#     def forward(self, customer_embeds, vehicle_embeds, decoder_hidden, last_hh):
#         batch_size = customer_embeds.size(0)
        
#         # Update LSTM
#         rnn_out, last_hh = self.lstm(decoder_hidden.transpose(2, 1), last_hh)
#         rnn_out = rnn_out.squeeze(1)
#         rnn_out = self.drop_rnn(rnn_out)
        
#         if self.num_layers == 1:
#             h_n, c_n = last_hh
#             h_n = self.drop_hh(h_n)
#             last_hh = (h_n, c_n)
        
#         # --- Attention Mechanism ---
        
#         # 1. Global Context
#         C_node = customer_embeds.mean(dim=2, keepdim=True) 
#         C_veh = vehicle_embeds.mean(dim=2, keepdim=True)   
        
#         # 2. Vehicle Selection Attention
#         h_expanded = rnn_out.unsqueeze(2).expand_as(vehicle_embeds)
#         C_node_expanded = C_node.expand_as(vehicle_embeds)
        
#         veh_input = torch.cat([C_node_expanded, h_expanded, vehicle_embeds], dim=1) 
        

#         v_veh = self.v_veh.expand(batch_size, -1, -1)
#         W_veh = self.W_veh.expand(batch_size, -1, -1)
        
#         veh_energy = torch.bmm(v_veh, torch.tanh(torch.bmm(W_veh, veh_input)))
#         veh_probs = veh_energy.squeeze(1)
        
#         # 3. Customer Selection Attention
#         h_expanded_node = rnn_out.unsqueeze(2).expand_as(customer_embeds)
#         C_veh_expanded = C_veh.expand_as(customer_embeds)
        
#         node_input = torch.cat([C_veh_expanded, h_expanded_node, customer_embeds], dim=1)
        
#         v_node = self.v_node.expand(batch_size, -1, -1)
#         W_node = self.W_node.expand(batch_size, -1, -1)
        
#         node_energy = torch.bmm(v_node, torch.tanh(torch.bmm(W_node, node_input)))
#         node_probs = node_energy.squeeze(1)
        
#         return veh_probs, node_probs, last_hh

# class MOPVRP_Actor(nn.Module):
#     def __init__(self, static_size, dynamic_size_truck, dynamic_size_drone, 
#                  hidden_size, num_layers=1, dropout=0.2):
#         super(MOPVRP_Actor, self).__init__()
        
#         # Encoders
#         self.static_encoder = Encoder(static_size, hidden_size)
#         self.truck_encoder = Encoder(dynamic_size_truck, hidden_size)
#         self.drone_encoder = Encoder(dynamic_size_drone, hidden_size)
        
#         # Decoder input is 2D (x, y) coordinates of the last visited node
#         self.decoder = Encoder(2, hidden_size) 
#         self.pointer = MultiAgentDecoder(hidden_size, num_layers, dropout)
        
#         # Learnable initial placeholder for decoder input
#         self.x0 = nn.Parameter(torch.zeros(1, 2, 1)) 
    
#     def forward(self, static, dynamic_trucks, dynamic_drones, 
#                 decoder_input=None, last_hh=None, mask_customers=None, mask_vehicles=None):
        
#         batch_size = static.size(0)
        
#         # Prepare Decoder Input (First step uses x0)
#         if decoder_input is None:
#             decoder_input = self.x0.expand(batch_size, -1, -1)
        
#         # Prepare Masks
#         if mask_customers is None:
#             mask_customers = torch.ones(batch_size, static.size(2), device=static.device)
#         if mask_vehicles is None:
#             num_veh = dynamic_trucks.size(2) + dynamic_drones.size(2)
#             mask_vehicles = torch.ones(batch_size, num_veh, device=static.device)
        
#         # --- 1. Encoding ---
#         customer_hidden = self.static_encoder(static)      # (B, 128, N)
#         truck_hidden = self.truck_encoder(dynamic_trucks)  # (B, 128, T)
#         drone_hidden = self.drone_encoder(dynamic_drones)  # (B, 128, D)
        
#         # Combine vehicles
#         vehicle_hidden = torch.cat([truck_hidden, drone_hidden], dim=2) # (B, 128, T+D)
        
#         # --- 2. Decoding Step ---
#         decoder_hidden = self.decoder(decoder_input)
        
#         veh_logits, node_logits, last_hh = self.pointer(
#             customer_hidden, vehicle_hidden, decoder_hidden, last_hh
#         )
        
#         # --- 3. Masking & Softmax ---
#         # Masking: Set logits of invalid actions to -inf
#         # mask = 1 (valid), 0 (invalid)
#         veh_logits = veh_logits.masked_fill(mask_vehicles == 0, float('-inf'))
#         node_logits = node_logits.masked_fill(mask_customers == 0, float('-inf'))
        
#         veh_probs = F.softmax(veh_logits, dim=1)
#         node_probs = F.softmax(node_logits, dim=1)
        
#         return veh_probs, node_probs, last_hh

# class Critic(nn.Module):
#     def __init__(self, static_size, dynamic_size_truck, dynamic_size_drone, hidden_size):
#         super(Critic, self).__init__()
#         self.static_conv = nn.Conv1d(static_size, hidden_size, kernel_size=1)
#         self.truck_conv = nn.Conv1d(dynamic_size_truck, hidden_size, kernel_size=1)
#         self.drone_conv = nn.Conv1d(dynamic_size_drone, hidden_size, kernel_size=1)
#         self.fc1 = nn.Linear(hidden_size * 3, hidden_size)
#         self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
#         self.fc3 = nn.Linear(hidden_size // 2, 1)
#         self.relu = nn.ReLU()
#         self.dropout = nn.Dropout(0.1)
        
#     # def forward(self, static, dynamic_trucks, dynamic_drones):
#     #     static_embed = self.static_conv(static)
#     #     truck_embed = self.truck_conv(dynamic_trucks)
#     #     drone_embed = self.drone_conv(dynamic_drones)
#     #     combined = torch.cat([static_embed.mean(2), truck_embed.mean(2), drone_embed.mean(2)], dim=1)
#     #     x = self.relu(self.fc1(combined))
#     #     x = self.dropout(x)
#     #     x = self.relu(self.fc2(x))
#     #     x = self.dropout(x)
#     #     return self.fc3(x).squeeze(-1)

#     def forward(self, static, dynamic_trucks, dynamic_drones):
#         # 1. Th√™m ReLU cho ph·∫ßn Embedding ƒë·ªÉ tr√≠ch xu·∫•t t√≠nh ch·∫•t phi tuy·∫øn
#         static_embed = self.relu(self.static_conv(static))
#         truck_embed = self.relu(self.truck_conv(dynamic_trucks))
#         drone_embed = self.relu(self.drone_conv(dynamic_drones))
        
#         # 2. Global Average Pooling (Gi·ªØ nguy√™n logic c·ªßa b·∫°n)
#         combined = torch.cat([
#             static_embed.mean(2), 
#             truck_embed.mean(2), 
#             drone_embed.mean(2)
#         ], dim=1)
        
#         # 3. C√°c l·ªõp Fully Connected
#         x = self.relu(self.fc1(combined))
#         x = self.dropout(x)
#         x = self.relu(self.fc2(x))
#         x = self.dropout(x)
        
#         # 4. L·ªõp Output: Tuy·ªát ƒë·ªëi kh√¥ng c√≥ Activation
#         # Squeeze dim=1 ƒë·ªÉ ƒë·∫£m b·∫£o lu√¥n gi·ªØ l·∫°i dim c·ªßa Batch
#         return self.fc3(x).squeeze(1)

import torch
import torch.nn as nn
import torch.nn.functional as F

class PairwiseEmbedding(nn.Module):
    """
    T·∫°o vector embedding cho t·ª´ng c·∫∑p (Vehicle, Customer).
    Input: Static (Customer) & Dynamic (Vehicle)
    Output: Tensor [Batch, Hidden, Num_Vehicles, Num_Customers]
    """
    def __init__(self, static_size, dynamic_size, hidden_size):
        super(PairwiseEmbedding, self).__init__()
        # Input size = feature tƒ©nh + feature ƒë·ªông
        self.conv2d = nn.Conv2d(static_size + dynamic_size, hidden_size, kernel_size=1)
        
    def forward(self, static, dynamic):
        """
        static: [Batch, Static_Feat, Num_Customers]
        dynamic: [Batch, Dyn_Feat, Num_Vehicles]
        """
        B, S_Feat, N_Cust = static.size()
        _, D_Feat, N_Veh = dynamic.size()
        
        # 1. Broadcasting ƒë·ªÉ kh·ªõp k√≠ch th∆∞·ªõc
        # Static: [B, S_Feat, 1, N_Cust] -> L·∫∑p l·∫°i cho m·ªçi Vehicle
        static_expanded = static.unsqueeze(2).expand(-1, -1, N_Veh, -1)
        
        # Dynamic: [B, D_Feat, N_Veh, 1] -> L·∫∑p l·∫°i cho m·ªçi Customer
        dynamic_expanded = dynamic.unsqueeze(3).expand(-1, -1, -1, N_Cust)
        
        # 2. Concatenate: [B, S+D, N_Veh, N_Cust]
        combined = torch.cat([static_expanded, dynamic_expanded], dim=1)
        
        # 3. Embedding (Conv2d kernel 1 t∆∞∆°ng ƒë∆∞∆°ng Linear cho t·ª´ng c·∫∑p)
        # Output: [B, Hidden, N_Veh, N_Cust]
        pairwise_embeds = self.conv2d(combined)
        return pairwise_embeds

class HierarchicalDecoder(nn.Module):
    def __init__(self, hidden_size, dropout=0.1):
        super(HierarchicalDecoder, self).__init__()
        self.hidden_size = hidden_size
        
        # LSTM ƒë·ªÉ nh·ªõ ng·ªØ c·∫£nh qu√° kh·ª© (History)
        self.lstm = nn.LSTMCell(hidden_size, hidden_size)
        
        # --- Attention cho b∆∞·ªõc 1: Ch·ªçn Vehicle ---
        # Query: LSTM State + Global Context
        # Key: Vehicle Representation (Aggregated from customers)
        self.W_veh = nn.Linear(hidden_size * 2, hidden_size) # Project Context
        self.v_veh = nn.Parameter(torch.rand(hidden_size))
        
        # --- Attention cho b∆∞·ªõc 2: Ch·ªçn Customer ---
        # Query: LSTM State + Selected Vehicle Info
        # Key: Pairwise Embedding c·ªßa (Selected Vehicle, Customers)
        self.W_cust = nn.Linear(hidden_size * 2, hidden_size)
        self.v_cust = nn.Parameter(torch.rand(hidden_size))
        
    def forward(self, pairwise_embeds, decoder_input, last_hh, mask_veh=None, mask_cust=None, deterministic=False):
        """
        pairwise_embeds: [B, H, N_Veh, N_Cust]
        decoder_input: [B, H] (Embedding c·ªßa node v·ª´a gh√© thƒÉm)
        """
        h_t, c_t = last_hh
        h_t, c_t = self.lstm(decoder_input, (h_t, c_t)) # Update LSTM
        
        B, H, N_Veh, N_Cust = pairwise_embeds.size()
        
        # =========================================================
        # B∆Ø·ªöC 1: CH·ªåN VEHICLE (Vehicle Selection)
        # =========================================================
        
        # 1. T·∫°o Vector ƒë·∫°i di·ªán cho t·ª´ng Vehicle
        # B·∫±ng c√°ch: G·ªôp (Mean Pooling) t·∫•t c·∫£ Customer t∆∞∆°ng ·ª©ng v·ªõi Vehicle ƒë√≥
        # Shape: [B, H, N_Veh, N_Cust] -> [B, H, N_Veh]
        veh_repr = pairwise_embeds.mean(dim=3) 
        
        # 2. T√≠nh ƒëi·ªÉm (Attention Score) cho t·ª´ng Vehicle
        # Context g·ªìm: LSTM output (h_t) m·ªü r·ªông
        # Score = v^T * tanh(W_veh * [veh_repr; h_t])
        
        h_t_expanded_v = h_t.unsqueeze(2).expand(-1, -1, N_Veh) # [B, H, V]
        
        # G·ªôp Vehicle Rep v√† LSTM Context (theo chi·ªÅu feature dim 1)
        # Input cho attention: [B, 2*H, V] -> transpose -> [B, V, 2*H]
        veh_att_input = torch.cat([veh_repr, h_t_expanded_v], dim=1).transpose(1, 2)
        
        # T√≠nh Energy: [B, V, H] -> [B, V]
        veh_energy = torch.matmul(torch.tanh(self.W_veh(veh_att_input)), self.v_veh)
        
        # Masking & Softmax
        if mask_veh is not None:
            veh_energy = veh_energy.masked_fill(mask_veh == 0, float('-inf'))
        veh_probs = F.softmax(veh_energy, dim=1)
        
        # 3. Ch·ªçn Vehicle (Sampling ho·∫∑c Greedy)
        if deterministic:
            selected_veh_idx = torch.argmax(veh_probs, dim=1) # [B]
        else:
            dist = torch.distributions.Categorical(veh_probs)
            selected_veh_idx = dist.sample() # [B]

        # =========================================================
        # B∆Ø·ªöC 2: CH·ªåN CUSTOMER (Customer Selection)
        # =========================================================
        
        # 1. L·∫•y vector c·∫∑p c·ªßa (Vehicle ƒê∆Ø·ª¢C CH·ªåN, T·∫•t c·∫£ Customers)
        # Ch√∫ng ta c·∫ßn l·∫•y l√°t c·∫Øt (slice) t∆∞∆°ng ·ª©ng v·ªõi selected_veh_idx
        
        # T·∫°o index ƒë·ªÉ gather: [B, H, 1, N_Cust]
        idx_view = selected_veh_idx.view(B, 1, 1, 1).expand(-1, H, 1, N_Cust)
        # idx_view = pairwise_embeds[: : , : : , selected_veh_idx, : : ]
        
        # Gather: L·∫•y ra [B, H, 1, N_Cust] -> squeeze -> [B, H, N_Cust]
        # ƒê√¢y l√† vector ƒë·∫∑c tr∆∞ng c·ªßa vi·ªác "Vehicle X ƒëi ƒë·∫øn t·ª´ng Customer"
        selected_veh_cust_embeds = pairwise_embeds.gather(2, idx_view).squeeze(2)
        print("Embedding: ", selected_veh_cust_embeds)
        
        # 2. T√≠nh ƒëi·ªÉm cho t·ª´ng Customer
        # Context: LSTM output (h_t)
        h_t_expanded_c = h_t.unsqueeze(2).expand(-1, -1, N_Cust) # [B, H, N]
        
        # Input: [Pairwise(V_selected, C); h_t]
        cust_att_input = torch.cat([selected_veh_cust_embeds, h_t_expanded_c], dim=1).transpose(1, 2)
        
        # T√≠nh Energy: [B, N]
        cust_energy = torch.matmul(torch.tanh(self.W_cust(cust_att_input)), self.v_cust)
        
        # Masking & Softmax
        if mask_cust is not None:
            cust_energy = cust_energy.masked_fill(mask_cust == 0, float('-inf'))
        cust_probs = F.softmax(cust_energy, dim=1)
        
        # Tr·∫£ v·ªÅ c·∫£ index xe ƒë√£ ch·ªçn ƒë·ªÉ b√™n ngo√†i bi·∫øt
        return veh_probs, cust_probs, selected_veh_idx, (h_t, c_t)


class MOPVRP_Actor(nn.Module):
    def __init__(self, static_size, dynamic_size_truck, dynamic_size_drone, 
                 hidden_size, dropout=0.1):
        super(MOPVRP_Actor, self).__init__()
        
        # T·ª± ƒë·ªông t√≠nh k√≠ch th∆∞·ªõc Dynamic l·ªõn nh·∫•t ƒë·ªÉ Padding
        self.max_dyn_size = max(dynamic_size_truck, dynamic_size_drone)
        
        # Encoder t·∫°o ma tr·∫≠n c·∫∑p
        self.pairwise_encoder = PairwiseEmbedding(static_size, self.max_dyn_size, hidden_size)
        
        # Embed t·ªça ƒë·ªô (x,y) c·ªßa node tr∆∞·ªõc ƒë√≥ l√†m input cho LSTM
        self.coords_embedding = nn.Linear(2, hidden_size)
        
        # Decoder ch√≠nh
        self.decoder = HierarchicalDecoder(hidden_size)
        
        # Learnable initial state
        self.x0 = nn.Parameter(torch.zeros(1, 2))
        self.h0 = nn.Parameter(torch.zeros(1, hidden_size))
        self.c0 = nn.Parameter(torch.zeros(1, hidden_size))
        
        # Kh·ªüi t·∫°o tr·ªçng s·ªë
        self._init_weights()

    def _init_weights(self):
        """Kh·ªüi t·∫°o c∆° b·∫£n"""
        for name, param in self.named_parameters():
            if 'weight' in name and param.dim() > 1:
                nn.init.xavier_uniform_(param)
            if 'bias' in name:
                nn.init.constant_(param, 0)
    
    def _pad_and_combine_vehicles(self, trucks, drones):
        """
        H√†m helper: Padding feature v√† g·ªôp Truck + Drone th√†nh 1 tensor
        Trucks: [B, F_T, N_T]
        Drones: [B, F_D, N_D]
        Output: [B, Max_F, N_T + N_D]
        """
        # Pad Truck
        diff_t = self.max_dyn_size - trucks.size(1)
        if diff_t > 0:
            pad_t = torch.zeros(trucks.size(0), diff_t, trucks.size(2), device=trucks.device)
            trucks = torch.cat([trucks, pad_t], dim=1)
            
        # Pad Drone
        diff_d = self.max_dyn_size - drones.size(1)
        if diff_d > 0:
            pad_d = torch.zeros(drones.size(0), diff_d, drones.size(2), device=drones.device)
            drones = torch.cat([drones, pad_d], dim=1)
            
        # G·ªôp l·∫°i
        return torch.cat([trucks, drones], dim=2)

    def forward(self, static, dynamic_trucks, dynamic_drones, 
                decoder_input=None, last_hh=None, mask_customers=None, mask_vehicles=None, deterministic=False):
        
        batch_size = static.size(0)
        
        # 1. X·ª≠ l√Ω Input: Padding & Combine
        dynamic_vehicles = self._pad_and_combine_vehicles(dynamic_trucks, dynamic_drones)
        
        # 2. T·∫°o Pairwise Embedding [B, H, V, N]
        pairwise_embeds = self.pairwise_encoder(static, dynamic_vehicles)
        
        # 3. Chu·∫©n b·ªã LSTM Input
        if decoder_input is None:
            decoder_input = self.x0.expand(batch_size, -1)
        
        decoder_input_embed = self.coords_embedding(decoder_input)
        
        if last_hh is None:
            last_hh = (self.h0.expand(batch_size, -1), self.c0.expand(batch_size, -1))
            
        # 4. Gi·∫£i m√£ Hierarchical
        # L∆∞u √Ω: H√†m n√†y tr·∫£ th√™m selected_veh_idx v√¨ n√≥ ƒë∆∞·ª£c ch·ªçn n·ªôi b·ªô
        veh_probs, node_probs, selected_veh_idx, last_hh = self.decoder(
            pairwise_embeds, 
            decoder_input_embed, 
            last_hh, 
            mask_vehicles, 
            mask_customers,
            deterministic
        )
        
        # Tr·∫£ v·ªÅ d·∫°ng (Veh_Probs, Node_Probs, Last_HH) nh∆∞ c≈©
        # Nh∆∞ng L∆ØU √ù: Trong v√≤ng l·∫∑p training PPO, b·∫°n n√™n s·ª≠ d·ª•ng `selected_veh_idx` 
        # ƒë∆∞·ª£c tr·∫£ v·ªÅ t·ª´ model n√†y thay v√¨ sample l·∫°i b√™n ngo√†i (ƒë·ªÉ ƒë·ªìng b·ªô).
        # Tuy nhi√™n, ƒë·ªÉ kh·ªõp API c≈©, ta tr·∫£ v·ªÅ c√°c bi·∫øn ch√≠nh.
        
        # Hack nh·∫π: G·∫Øn selected_veh_idx v√†o tuple tr·∫£ v·ªÅ ho·∫∑c x·ª≠ l√Ω ·ªü PPOTrainer
        # ·ªû ƒë√¢y t√¥i tr·∫£ v·ªÅ th√™m 1 bi·∫øn th·ª© 4, b·∫°n ch·ªâ c·∫ßn s·ª≠a d√≤ng g·ªçi h√†m trong PPOTrainer l√†:
        # veh_probs, node_probs, last_hh, internal_veh_idx = model(...)
        
        return veh_probs, node_probs, selected_veh_idx, last_hh

    # ======================================================================
    # NEW METHOD ADDED: PERTURB WEIGHTS (Ch·ªâ d√πng khi Test/Debug)
    # ======================================================================
    def perturb_weights(self, noise_scale=1.0):
        """
        Th√™m nhi·ªÖu m·∫°nh ƒë·ªÉ ph√° v·ª° th·∫ø k·∫πt (Local Optima) cho ki·∫øn tr√∫c Hierarchical.
        """
        print(f"‚ö° [Hierarchical_Actor] Adding STRONG noise (scale={noise_scale})...")
        with torch.no_grad():
            # 1. Nhi·ªÖu Encoder (Pairwise Conv2d)
            # Thay th·∫ø ho√†n to√†n tr·ªçng s·ªë b·∫±ng ph√¢n ph·ªëi Uniform r·ªông (Reset m·∫°nh)
            if hasattr(self.pairwise_encoder, 'conv2d'):
                self.pairwise_encoder.conv2d.weight.data.uniform_(-noise_scale, noise_scale)
                if self.pairwise_encoder.conv2d.bias is not None:
                     self.pairwise_encoder.conv2d.bias.data.uniform_(-noise_scale, noise_scale)

            # 2. Nhi·ªÖu Decoder (Hierarchical Steps)
            # V·ªõi c√°c l·ªõp Linear (W), ta c·ªông th√™m nhi·ªÖu (Additive Noise) thay v√¨ thay th·∫ø
            # ƒë·ªÉ gi·ªØ l·∫°i m·ªôt ph·∫ßn ki·∫øn th·ª©c ƒë√£ h·ªçc nh∆∞ng l√†m rung chuy·ªÉn n√≥.
            
            # --- Nh√°nh ch·ªçn Vehicle ---
            self.decoder.W_veh.weight.data += torch.randn_like(self.decoder.W_veh.weight.data) * noise_scale
            self.decoder.v_veh.data.normal_(0, noise_scale * 2) # Vector v reset m·∫°nh
            
            # --- Nh√°nh ch·ªçn Customer ---
            self.decoder.W_cust.weight.data += torch.randn_like(self.decoder.W_cust.weight.data) * noise_scale
            self.decoder.v_cust.data.normal_(0, noise_scale * 2) # Vector v reset m·∫°nh
            
        print("‚úì Hierarchical Weights perturbed successfully.")

    def _init_weights_high_variance(self):
        """
        Kh·ªüi t·∫°o tr·ªçng s·ªë v·ªõi ph∆∞∆°ng sai l·ªõn ƒë·ªÉ ph√° v·ª° t√≠nh ƒë·ªëi x·ª©ng ban ƒë·∫ßu.
        Gi√∫p model kh√¥ng b·ªã t√¨nh tr·∫°ng ch·ªçn t·∫•t c·∫£ c√°c xe/kh√°ch v·ªõi x√°c su·∫•t ngang nhau (50/50).
        """
        scale_factor = 2.0  # Std l·ªõn ƒë·ªÉ t·∫°o logit l·ªõn -> Softmax nh·ªçn (Sharp)
        
        with torch.no_grad():
            # 1. C√°c ma tr·∫≠n chi·∫øu (Linear Projection - W)
            # Gi·ªØ Xavier ƒë·ªÉ ƒë·∫£m b·∫£o lu·ªìng gradient ·ªïn ƒë·ªãnh qua tanh()
            nn.init.xavier_uniform_(self.decoder.W_veh.weight)
            nn.init.xavier_uniform_(self.decoder.W_cust.weight)
            
            # N·∫øu c√≥ bias th√¨ ƒë∆∞a v·ªÅ 0
            if self.decoder.W_veh.bias is not None: nn.init.zeros_(self.decoder.W_veh.bias)
            if self.decoder.W_cust.bias is not None: nn.init.zeros_(self.decoder.W_cust.bias)

            # 2. C√°c vector nƒÉng l∆∞·ª£ng (Scoring Vectors - v)
            # D√πng Normal distribution v·ªõi ƒë·ªô l·ªách chu·∫©n L·ªöN
            # ƒêi·ªÅu n√†y khi·∫øn ƒëi·ªÉm Energy ban ƒë·∫ßu dao ƒë·ªông m·∫°nh, gi√∫p m√¥ h√¨nh
            # "d√°m" ƒë∆∞a ra quy·∫øt ƒë·ªãnh d·ª©t kho√°t ngay t·ª´ ƒë·∫ßu thay v√¨ ng·∫≠p ng·ª´ng.
            nn.init.normal_(self.decoder.v_veh, mean=0.0, std=scale_factor)
            nn.init.normal_(self.decoder.v_cust, mean=0.0, std=scale_factor)
            
            # 3. Pairwise Encoder
            # Kh·ªüi t·∫°o Kaiming cho Conv2d (t·ªët cho ReLU/Non-linearity sau ƒë√≥)
            nn.init.kaiming_normal_(self.pairwise_encoder.conv2d.weight, mode='fan_out', nonlinearity='relu')
        
        print(f"‚ö° Weights initialized with High Variance (std={scale_factor}) to force random bias.")

class Critic(nn.Module):
    def __init__(self, static_size, dynamic_size_truck, dynamic_size_drone, hidden_size):
        super(Critic, self).__init__()
        self.static_conv = nn.Conv1d(static_size, hidden_size, kernel_size=1)
        self.truck_conv = nn.Conv1d(dynamic_size_truck, hidden_size, kernel_size=1)
        self.drone_conv = nn.Conv1d(dynamic_size_drone, hidden_size, kernel_size=1)
        self.fc1 = nn.Linear(hidden_size * 3, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
        self.fc3 = nn.Linear(hidden_size // 2, 1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.1)
        
    # def forward(self, static, dynamic_trucks, dynamic_drones):
    #     static_embed = self.static_conv(static)
    #     truck_embed = self.truck_conv(dynamic_trucks)
    #     drone_embed = self.drone_conv(dynamic_drones)
    #     combined = torch.cat([static_embed.mean(2), truck_embed.mean(2), drone_embed.mean(2)], dim=1)
    #     x = self.relu(self.fc1(combined))
    #     x = self.dropout(x)
    #     x = self.relu(self.fc2(x))
    #     x = self.dropout(x)
    #     return self.fc3(x).squeeze(-1)

    def forward(self, static, dynamic_trucks, dynamic_drones):
        # 1. Th√™m ReLU cho ph·∫ßn Embedding ƒë·ªÉ tr√≠ch xu·∫•t t√≠nh ch·∫•t phi tuy·∫øn
        static_embed = self.relu(self.static_conv(static))
        truck_embed = self.relu(self.truck_conv(dynamic_trucks))
        drone_embed = self.relu(self.drone_conv(dynamic_drones))
        
        # 2. Global Average Pooling (Gi·ªØ nguy√™n logic c·ªßa b·∫°n)
        combined = torch.cat([
            static_embed.mean(2), 
            truck_embed.mean(2), 
            drone_embed.mean(2)
        ], dim=1)
        
        # 3. C√°c l·ªõp Fully Connected
        x = self.relu(self.fc1(combined))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        
        # 4. L·ªõp Output: Tuy·ªát ƒë·ªëi kh√¥ng c√≥ Activation
        # Squeeze dim=1 ƒë·ªÉ ƒë·∫£m b·∫£o lu√¥n gi·ªØ l·∫°i dim c·ªßa Batch
        return self.fc3(x).squeeze(1)


# def check_model_compatibility():
#     print("\nüöÄ STARTING COMPATIBILITY CHECK...")
    
#     # 1. Setup
#     DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     BATCH_SIZE = 4
#     HIDDEN_SIZE = 128
    
#     # K√≠ch th∆∞·ªõc ƒë·∫∑c tr∆∞ng theo DataLoader
#     STATIC_SIZE = 4       # x, y, demand, type
#     DYN_TRUCK_SIZE = 2    # loc, time
#     DYN_DRONE_SIZE = 4    # loc, time, energy, payload
    
#     # 2. Init Model
#     print(f"üîπ Initializing Model on {DEVICE}...")
#     model = MOPVRP_Actor(
#         static_size=STATIC_SIZE,
#         dynamic_size_truck=DYN_TRUCK_SIZE,
#         dynamic_size_drone=DYN_DRONE_SIZE,
#         hidden_size=HIDDEN_SIZE
#     ).to(DEVICE)



#     # =================================================================
#     # QUAN TR·ªåNG: G·ªåI H√ÄM L√ÄM NHI·ªÑU ·ªû ƒê√ÇY
#     # =================================================================
#     try:
#         checkpoint_path = "/Users/nguyentrithanh/Documents/20251/Project3/IT3940E-RL_for_MOVRP/ptr-net/checkpoints/checkpoint_epoch_497.pth"  # ƒê∆∞·ªùng d·∫´n checkpoint n·∫øu c√≥
    
#         checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)
#         model.load_state_dict(checkpoint["actor_state_dict"])
#         # G·ªçi h√†m perturb_weights v·ªõi noise l·ªõn ƒë·ªÉ th·∫•y r√µ s·ª± kh√°c bi·ªát
#         model.perturb_weights(noise_scale=1.0)
#         model._init_weights_high_variance()
#     except:
#         print("‚ö†Ô∏è Warning: Model ch∆∞a c√≥ h√†m perturb_weights. H√£y c·∫≠p nh·∫≠t class MOPVRP_Actor tr∆∞·ªõc.")
#     # =================================================================
    
#     # 3. Init DataLoader
#     print("üîπ Initializing DataLoader...")
#     # Gi·∫£ s·ª≠ b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a class MOPVRPGenerator ·ªü tr√™n
#     dataloader = get_rl_dataloader(batch_size=BATCH_SIZE, device=DEVICE)
#     data_iter = iter(dataloader)
    
#     # 4. Run Test
#     try:
#         # L·∫•y 1 batch
#         print("üîπ Fetching Batch data...")
#         static, dyn_trucks, dyn_drones, mask_cust, mask_veh, scale, weights = next(data_iter)
        
#         batch_size, _, num_nodes = static.shape
#         num_trucks = dyn_trucks.shape[2]
#         num_drones = dyn_drones.shape[2]
        
#         print(f"   Input Shapes:")
#         print(f"   - Static: {static.shape}")
#         print(f"   - Trucks: {dyn_trucks.shape}")
#         print(f"   - Drones: {dyn_drones.shape}")

#         # --- CAN THI·ªÜP TH·ª¶ C√îNG ƒê·ªÇ TEST (Nuclear Option) ---
#         print("\n‚ò¢Ô∏è  MANUALLY HACKING WEIGHTS TO FORCE SKEW...")
#         with torch.no_grad():
#             # 1. √âp xe ƒë·∫ßu ti√™n (Index 0) c√≥ ƒëi·ªÉm s·ªë c·ª±c cao
#             # model.pointer.v_veh shape: (1, 1, hidden)
#             # Ta c·ªông m·ªôt s·ªë r·∫•t l·ªõn v√†o ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa vector v
#             model.pointer.v_veh.data.fill_(10.0) # TƒÉng ƒë·ªô l·ªõn vector v l√™n
            
#             # √âp bias c·ªßa xe ƒë·∫ßu ti√™n trong l·ªõp Linear W_veh (n·∫øu c√≥)
#             # Nh∆∞ng ·ªü ƒë√¢y W_veh kh√¥ng c√≥ bias, ta hack v√†o input trucks
#             # Thay v√†o ƒë√≥, ta hack tr·ª±c ti·∫øp v√†o decoder output c·ªßa xe
            
#             # C√°ch hi·ªáu qu·∫£ nh·∫•t: Hack v√†o l·ªõp Conv1d c·ªßa Truck Encoder
#             # L√†m cho ƒë·∫∑c tr∆∞ng c·ªßa Truck 0 c·ª±c k·ª≥ kh√°c bi·ªát so v·ªõi c√°c xe kh√°c
#             # Truck Encoder weights: (hidden, input_size, 1)
#             model.truck_encoder.conv.weight.data.normal_(0, 5.0) 
#             model.drone_encoder.conv.weight.data.normal_(0, 2.0) # Drone nh·ªè x√≠u
            
#             # Hack v√†o v_node ƒë·ªÉ l√†m l·ªách Node Probs
#             model.pointer.v_node.data.normal_(0, 5.0)
            
#         print("‚úÖ Weights hacked successfully.")
#         # ---------------------------------------------------

        
#         # Forward Pass
#         print("üîπ Running Forward Pass...")
#         veh_probs, node_probs, last_hh = model(
#             static, dyn_trucks, dyn_drones, 
#             decoder_input=None, 
#             last_hh=None, 
#             mask_customers=mask_cust, 
#             mask_vehicles=mask_veh
#         )
        
#         print("‚úÖ Forward Pass Successful!")
#         print(f"   Output Shapes:")
#         print(f"   - Vehicle Probs: {veh_probs.shape} (Expected: [{batch_size}, {num_trucks + num_drones}])")
#         print(f"   - Node Probs:    {node_probs.shape} (Expected: [{batch_size}, {num_nodes}])")

#         print(f"   Output Explicit Probability:")
#         print(f"   - Vehicle Probs: {veh_probs.detach().cpu().numpy()}")
#         print(f"   - Node Probs:    {node_probs.detach().cpu().numpy()}")
        
#         # Ki·ªÉm tra t·ªïng x√°c su·∫•t = 1
#         print(f"   - Sum Vehicle Probs: {veh_probs.sum(dim=1).detach().cpu().numpy()}")
#         print(f"   - Sum Node Probs:    {node_probs.sum(dim=1).detach().cpu().numpy()}")
        
#     except Exception as e:
#         print(f"\n‚ùå FAILED! Error: {e}")
#         import traceback
#         traceback.print_exc()

# if __name__ == "__main__":
#     check_model_compatibility()

import torch
import torch.nn.functional as F

def check_model_compatibility():
    print("\nüöÄ STARTING HIERARCHICAL MODEL COMPATIBILITY CHECK...")
    
    # 1. Setup
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    BATCH_SIZE = 4
    HIDDEN_SIZE = 128
    
    # K√≠ch th∆∞·ªõc ƒë·∫∑c tr∆∞ng gi·∫£ ƒë·ªãnh (M√¥ ph·ªèng d·ªØ li·ªáu th·∫≠t c·ªßa b·∫°n)
    STATIC_SIZE = 4       # x, y, demand, type
    DYN_TRUCK_SIZE = 2    # loc, load (√çt feature h∆°n)
    DYN_DRONE_SIZE = 4    # loc, energy, payload, time (Nhi·ªÅu feature h∆°n)
    
    # K√≠ch th∆∞·ªõc Dynamic ƒë·∫ßu v√†o cho Model ph·∫£i l√† MAX c·ªßa 2 lo·∫°i xe
    # V√¨ ch√∫ng ta s·∫Ω padding th·∫±ng nh·ªè l√™n b·∫±ng th·∫±ng l·ªõn
    MAX_DYN_SIZE = max(DYN_TRUCK_SIZE, DYN_DRONE_SIZE)

    # 2. Init Hierarchical Model
    print(f"üîπ Initializing MOPVRP_HierarchicalActor on {DEVICE}...")
    # L∆∞u √Ω: Class m·ªõi ch·ªâ c·∫ßn 3 tham s·ªë n√†y
    model = MOPVRP_Actor(
        static_size=STATIC_SIZE,
        dynamic_size_truck=DYN_TRUCK_SIZE, 
        dynamic_size_drone=DYN_DRONE_SIZE,
        hidden_size=HIDDEN_SIZE
    ).to(DEVICE)

    # =================================================================
    # PH·∫¶N 3: KI·ªÇM TRA T√çNH NƒÇNG NHI·ªÑU (PERTURBATION CHECK)
    # =================================================================
    try:
        # ƒê∆∞·ªùng d·∫´n checkpoint (Gi·ªØ nguy√™n c·ªßa b·∫°n)
        checkpoint_path = "/Users/nguyentrithanh/Documents/20251/Project3/IT3940E-RL_for_MOVRP/ptr-net/checkpoints/checkpoint_epoch_497.pth" 
        
        # Th·ª≠ load (n·∫øu file t·ªìn t·∫°i)
        import os
        if os.path.exists(checkpoint_path):
            print(f"üîπ Loading checkpoint from {checkpoint_path}...")
            checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)
            # L∆∞u √Ω: Key state_dict c√≥ th·ªÉ kh√°c n·∫øu b·∫°n ƒë·ªïi t√™n class, c·∫ßn check k·ªπ
            # model.load_state_dict(checkpoint["actor_state_dict"], strict=False) 
        else:
            print("‚ö†Ô∏è Checkpoint file not found. Using random weights.")

        # G·ªçi h√†m perturb_weights m·ªõi
        print("‚ö° Testing perturb_weights()...")
        model.perturb_weights(noise_scale=5.0)
        model._init_weights_high_variance()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Warning during perturbation: {e}")
    # =================================================================
    
    # 4. T·∫°o D·ªØ li·ªáu Gi·∫£ l·∫≠p (Dummy Data) 
    # (T√¥i t·∫°o tr·ª±c ti·∫øp ƒë·ªÉ b·∫°n ch·∫°y ƒë∆∞·ª£c ngay m√† kh√¥ng c·∫ßn Dataloader)
    print("üîπ Generating Dummy Data with different dimensions...")
    
    NUM_NODES = 20
    NUM_TRUCKS = 2
    NUM_DRONES = 3
    
    # Static: [B, 4, N]
    static = torch.rand(BATCH_SIZE, STATIC_SIZE, NUM_NODES).to(DEVICE)
    
    # Dynamic Truck: [B, 2, T] (√çt chi·ªÅu)
    dyn_trucks_raw = torch.rand(BATCH_SIZE, DYN_TRUCK_SIZE, NUM_TRUCKS).to(DEVICE)
    
    # Dynamic Drone: [B, 4, D] (Nhi·ªÅu chi·ªÅu)
    dyn_drones_raw = torch.rand(BATCH_SIZE, DYN_DRONE_SIZE, NUM_DRONES).to(DEVICE)
    
    mask_cust = torch.ones(BATCH_SIZE, NUM_NODES).to(DEVICE)
    mask_veh = torch.ones(BATCH_SIZE, NUM_TRUCKS + NUM_DRONES).to(DEVICE)

    # 3. Init DataLoader
    print("üîπ Initializing DataLoader...")
    # Gi·∫£ s·ª≠ b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a class MOPVRPGenerator ·ªü tr√™n
    dataloader = get_rl_dataloader(batch_size=BATCH_SIZE, device=DEVICE)
    data_iter = iter(dataloader)

    print("üîπ Fetching Batch data...")
    static, dyn_trucks, dyn_drones, mask_cust, mask_veh, scale, weights = next(data_iter)

    batch_size, _, num_nodes = static.shape
    num_trucks = dyn_trucks.shape[2]
    num_drones = dyn_drones.shape[2]

    # print(f"   Input Shapes:")
    # print(f"   - Static: {static.shape}")
    # print(f"   - Trucks: {dyn_trucks.shape}")
    # print(f"   - Drones: {dyn_drones.shape}")
    

    # =================================================================
    # PH·∫¶N 5: PADDING LOGIC (QUAN TR·ªåNG)
    # =================================================================
    print(f"üîπ Processing Dynamic Features (Padding)...")
    print(f"   Original Truck Shape: {dyn_trucks.shape}")
    print(f"   Original Drone Shape: {dyn_drones.shape}")
    
    def pad_feature_dim(tensor, target_dim):
        """H√†m padding feature dimension (dim 1) cho b·∫±ng target_dim"""
        b, f, n = tensor.size()
        diff = target_dim - f
        if diff > 0:
            # T·∫°o tensor 0 c√≥ k√≠ch th∆∞·ªõc [B, diff, N]
            padding = torch.zeros(b, diff, n, device=tensor.device)
            # N·ªëi v√†o ƒëu√¥i feature
            return torch.cat([tensor, padding], dim=1)
        return tensor

    # Pad c·∫£ 2 lo·∫°i xe ƒë·ªÉ ƒë·∫£m b·∫£o c√πng s·ªë feature = MAX_DYN_SIZE
    dyn_trucks_padded = pad_feature_dim(dyn_trucks, MAX_DYN_SIZE)
    dyn_drones_padded = pad_feature_dim(dyn_drones, MAX_DYN_SIZE)
    
    print(f"   -> Padded Truck Shape: {dyn_trucks_padded.shape}")
    print(f"   -> Padded Drone Shape: {dyn_drones_padded.shape}")

    # =================================================================
    # PH·∫¶N 6: MANUAL HACKING (Update cho Hierarchical Model)
    # =================================================================
    # print("\n‚ò¢Ô∏è  MANUALLY HACKING WEIGHTS (HIERARCHICAL VERSION)...")
    # with torch.no_grad():
    #     # 1. Hack v√†o Pairwise Embedding (Conv2d)
    #     # L√†m cho ƒë·∫∑c tr∆∞ng c·ªßa c·∫∑p (Xe 0, Kh√°ch h√†ng) c·ª±c m·∫°nh
    #     # Pairwise Encoder: self.pairwise_encoder.conv2d
    #     print("   -> Hacking Pairwise Conv2d...")
    #     model.pairwise_encoder.conv2d.weight.data.normal_(0, 5.0) 
        
    #     # 2. Hack v√†o nh√°nh ch·ªçn Vehicle (W_veh, v_veh)
    #     # √âp model c·ª±c k·ª≥ thi√™n v·ªã khi ch·ªçn xe
    #     print("   -> Hacking Vehicle Selection Branch...")
    #     model.decoder.v_veh.data.fill_(10.0) # TƒÉng ƒë·ªô l·ªõn vector ch·∫•m ƒëi·ªÉm xe
    #     model.decoder.W_veh.weight.data.normal_(0, 5.0)

    #     # 3. Hack v√†o nh√°nh ch·ªçn Customer (W_cust, v_cust)
    #     print("   -> Hacking Customer Selection Branch...")
    #     model.decoder.v_cust.data.fill_(10.0) # TƒÉng ƒë·ªô l·ªõn vector ch·∫•m ƒëi·ªÉm kh√°ch
    #     model.decoder.W_cust.weight.data.normal_(0, 5.0)
        
    # print("‚úÖ Weights hacked successfully.")

    # =================================================================
    # PH·∫¶N 7: FORWARD PASS
    # =================================================================
    try:
        print("\nüîπ Running Forward Pass...")
        # L·∫•y 1 batch

        
        # L∆∞u √Ω: Truy·ªÅn v√†o tensor ƒê√É ƒê∆Ø·ª¢C PADDING
        veh_probs, node_probs, idx, last_hh = model(
            static, 
            dyn_trucks_padded, 
            dyn_drones_padded, 
            decoder_input=None, 
            last_hh=None, 
            mask_customers=mask_cust, 
            mask_vehicles=mask_veh
        )
        
        print("‚úÖ Forward Pass Successful!")
        print(f"\nüìä OUTPUT ANALYSIS:")
        
        # Check Shape
        expected_veh = NUM_TRUCKS + NUM_DRONES
        print(f"   - Vehicle Probs Shape: {veh_probs.shape} (Expected: [{BATCH_SIZE}, {expected_veh}])")
        print(f"   - Node Probs Shape:    {node_probs.shape} (Expected: [{BATCH_SIZE}, {NUM_NODES}])")
        print(f"   - Selected Index Shape: {idx.shape}")

        # Check Values
        print(f"\n   Example Probs (Batch 0):")
        print(f"   - Vehicle Probs: {veh_probs[0].detach().cpu().numpy().round(3)}")
        print(f"   - Node Probs:    {node_probs[0].detach().cpu().numpy().round(3)}")
        
        # Check Sum = 1
        sum_veh = veh_probs.sum(dim=1).detach().cpu().numpy()
        sum_node = node_probs.sum(dim=1).detach().cpu().numpy()
        print(f"\n   Probability Integrity Check (Should be all 1.0):")
        print(f"   - Sum Veh:  {sum_veh}")
        print(f"   - Sum Node: {sum_node}")
        
    except Exception as e:
        print(f"\n‚ùå FAILED! Error during forward pass: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_model_compatibility()